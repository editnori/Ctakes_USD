#!/usr/bin/env bash\nset -euo pipefail\n\nBASE_DIR="$(cd "$(dirname "$0")/.." && pwd)"\nENV_FILE="${BASE_DIR}/.ctakes_env"\nif [[ -f "${ENV_FILE}" ]]; then\n  # shellcheck disable=SC1090\n  source "${ENV_FILE}"\nfi\n\n\nusage() {\n  cat <<'USAGE'\nUsage: scripts/validate.sh -i <input_dir> -o <output_dir> [options]\nOptions:\n  --pipeline <core_sectioned_smoke|s_core_relations_smoke>   Combined pipeline variant (default: s_core_relations_smoke)\n  --limit <N>                              Copy the first N files into a temp dir before running (default: all)\n  --manifest <file>                        Compare outputs against a saved manifest (creates baseline if missing)\n  --canonicalize                           Rewrite outputs into a stable order before manifesting (default)\n  --no-canonicalize                        Skip canonical rewriting before manifesting\n  --deterministic                          Force single-threaded pipeline for reproducibility (default)\n  --no-deterministic                       Allow autoscale / multi-threaded pipeline\n  --dry-run                                Print the pipeline command instead of executing\n  --help                                   Show this help text\n\nRuns scripts/run_pipeline.sh with sensible defaults. Use --limit to perform a quick\nvalidation pass on a small sample of notes.\nUSAGE\n}\n\nPIPELINE_KEY="s_core_relations_smoke"\nIN_DIR=""\nOUT_DIR=""\nLIMIT=0\nDRY_RUN=0\nMANIFEST=""\nCANONICALIZE=1\nDETERMINISTIC=0\nSTATUS=0\n\nwhile [[ $# -gt 0 ]]; do\n  case "$1" in\n    -i|--input) IN_DIR="$2"; shift 2;;\n    -o|--output) OUT_DIR="$2"; shift 2;;\n    --pipeline) PIPELINE_KEY="$2"; shift 2;;\n    --limit) LIMIT="$2"; shift 2;;\n    --with-relations)\n      echo "[validate] --with-relations is implied for combined pipelines; ignoring." >&2\n      shift 1;;\n    --manifest) MANIFEST="$2"; shift 2;;\n    --canonicalize) CANONICALIZE=1; shift 1;;\n    --no-canonicalize) CANONICALIZE=0; shift 1;;\n    --deterministic) DETERMINISTIC=1; shift 1;;\n    --no-deterministic) DETERMINISTIC=0; shift 1;;\n    --dry-run) DRY_RUN=1; shift 1;;\n    --help|-h) usage; exit 0;;\n    *) echo "Unknown option: $1" >&2; usage >&2; exit 1;;\n  esac\n\ndone\n\ncase "${PIPELINE_KEY}" in\n  core_sectioned_smoke|s_core_relations_smoke)\n    ;;\n  *)\n    echo "[validate] Pipeline '${PIPELINE_KEY}' is no longer supported; using s_core_relations_smoke." >&2\n    PIPELINE_KEY="s_core_relations_smoke"\n    ;;\nesac\n\nif [[ -z "${IN_DIR}" || -z "${OUT_DIR}" ]]; then\n  echo "[validate] --input and --output are required" >&2\n  usage >&2\n  exit 1\nfi\n\nif ! [[ "${LIMIT}" =~ ^[0-9]+$ ]]; then\n  echo "[validate] --limit must be a non-negative integer" >&2\n  exit 1\nfi\n\nif [[ ! -d "${IN_DIR}" ]]; then\n  echo "[validate] Input directory does not exist: ${IN_DIR}" >&2\n  exit 1\nfi\n\nRUNNER="${BASE_DIR}/scripts/run_pipeline.sh"\nif [[ ! -f "${RUNNER}" ]]; then\n  echo "[validate] Missing run_pipeline.sh helper" >&2\n  exit 1\nfi\n\nRUNNER_CMD=("${BASH:-bash}" "${RUNNER}")\n\nPIPE_INPUT="${IN_DIR}"\nTMP_ROOT=""\nif [[ ${LIMIT} -gt 0 ]]; then\n  TMP_ROOT="$(mktemp -d "${TMPDIR:-/tmp}/ctakes_validate.XXXXXX")"\n  trap '[[ -n "${TMP_ROOT}" ]] && rm -rf "${TMP_ROOT}"' EXIT\n  PIPE_INPUT="${TMP_ROOT}/input"\n  mkdir -p "${PIPE_INPUT}"\n  PYTHON=$(command -v python3 || command -v python || true)\n  if [[ -z "${PYTHON}" ]]; then\n    echo "[validate] --limit requires python (python3 or python) to copy samples" >&2\n    exit 1\n  fi\n  "${PYTHON}" <<PY\nimport os, shutil\nsrc = os.path.abspath(${IN_DIR@Q})\ndest = os.path.abspath(${PIPE_INPUT@Q})\nlimit = int(${LIMIT@Q})\nallowed = {'.txt', '.xmi', '.xml'}\ncount = 0\nfor root, _, files in os.walk(src):\n    rel_root = os.path.relpath(root, src)\n    for name in sorted(files):\n        if limit and count >= limit:\n            break\n        ext = os.path.splitext(name)[1].lower()\n        if allowed and ext and ext not in allowed:\n            continue\n        src_path = os.path.join(root, name)\n        rel_path = name if rel_root == os.curdir else os.path.join(rel_root, name)\n        dest_path = os.path.join(dest, rel_path)\n        os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n        shutil.copy2(src_path, dest_path)\n        count += 1\n    if limit and count >= limit:\n        break\nif count == 0:\n    raise SystemExit('No files copied from %s (supported extensions: %s)' % (src, ', '.join(sorted(allowed))))\nprint('Copied %d file(s) into %s' % (count, dest))\nPY\nfi\n\nmkdir -p "${OUT_DIR}"\nARGS=("${RUNNER_CMD[@]}" -i "${PIPE_INPUT}" -o "${OUT_DIR}" --pipeline "${PIPELINE_KEY}")\nif [[ ${WITH_RELATIONS} -eq 1 ]]; then\n  ARGS+=(--with-relations)\nfi\n[[ ${DRY_RUN} -eq 1 ]] && ARGS+=(--dry-run)\nif [[ ${DETERMINISTIC} -eq 1 ]]; then\n  ARGS+=(--no-autoscale --threads 1 --xmx 4096)\nfi\n\nif [[ ${DRY_RUN} -eq 1 ]]; then\n  printf '[validate] '\n  printf '%q ' "${ARGS[@]}"\n  printf '\n'\n  exit 0\nfi\n\nif ! "${ARGS[0]}" "${ARGS[@]:1}"; then\n  STATUS=1\nfi\n\nfiles_processed=0\nif [[ -d "${OUT_DIR}/concepts" ]]; then\n  files_processed=$(find "${OUT_DIR}/concepts" -type f -name '*.csv' | wc -l | awk '{print $1}')\nfi\nif [[ ${STATUS} -eq 0 && ${CANONICALIZE} -eq 1 ]]; then\n  CANON_PY=$(command -v python3 || command -v python || true)\n  if [[ -z "${CANON_PY}" ]]; then\n    echo "[validate] --canonicalize requires python (python3 or python)." >&2\n    STATUS=1\n  else\n    "${CANON_PY}" - <<'PY' "${OUT_DIR}"\nimport csv\nimport pathlib\nimport sys\n\nbase = pathlib.Path(sys.argv[1]).resolve()\n\ndef int_or_zero(value):\n    try:\n        return int(value)\n    except Exception:\n        return 0\n\ndef rewrite_csv(path, sort_key):\n    with path.open('r', newline='', encoding='utf-8') as src:\n        reader = csv.reader(src)\n        try:\n            header = next(reader)\n        except StopIteration:\n            return\n        rows = list(reader)\n    if not rows:\n        return\n    rows.sort(key=lambda row: sort_key(header, row))\n    with path.open('w', newline='', encoding='utf-8') as dst:\n        writer = csv.writer(dst)\n        writer.writerow(header)\n        writer.writerows(rows)\n\ndef rewrite_bsv(path):\n    with path.open('r', encoding='utf-8') as src:\n        lines = src.readlines()\n    if not lines:\n        return\n    header, *data = lines\n    data = [line.rstrip('\n') for line in data if line.strip()]\n    if not data:\n        return\n    data.sort()\n    with path.open('w', encoding='utf-8') as dst:\n        dst.write(header)\n        for line in data:\n            dst.write(line)\n            dst.write('\n')\n\ndef concept_key(header, row):\n    begin_idx = header.index('core:Begin') if 'core:Begin' in header else -1\n    end_idx = header.index('core:End') if 'core:End' in header else -1\n    cui_idx = header.index('core:CUI') if 'core:CUI' in header else -1\n    return (\n        int_or_zero(row[begin_idx]) if 0 <= begin_idx < len(row) else 0,\n        int_or_zero(row[end_idx]) if 0 <= end_idx < len(row) else 0,\n        row[cui_idx] if 0 <= cui_idx < len(row) else '',\n        row,\n    )\n\ndef rxnorm_key(header, row):\n    begin_idx = header.index('Begin') if 'Begin' in header else -1\n    end_idx = header.index('End') if 'End' in header else -1\n    cui_idx = header.index('RxCUI') if 'RxCUI' in header else -1\n    return (\n        int_or_zero(row[begin_idx]) if 0 <= begin_idx < len(row) else 0,\n        int_or_zero(row[end_idx]) if 0 <= end_idx < len(row) else 0,\n        row[cui_idx] if 0 <= cui_idx < len(row) else '',\n        row,\n    )\n\nconcept_dir = base / 'concepts'\nif concept_dir.is_dir():\n    for csv_path in sorted(concept_dir.glob('*.csv')):\n        rewrite_csv(csv_path, concept_key)\n\ncui_dir = base / 'cui_counts'\nif cui_dir.is_dir():\n    for bsv_path in sorted(cui_dir.glob('*.bsv')):\n        rewrite_bsv(bsv_path)\n\nrx_dir = base / 'rxnorm'\nif rx_dir.is_dir():\n    for csv_path in sorted(rx_dir.glob('*.csv')):\n        rewrite_csv(csv_path, rxnorm_key)\nPY\n  fi\nfi\n\nif [[ ${STATUS} -eq 0 && -n "${MANIFEST}" ]]; then\n  PY_BIN=$(command -v python3 || command -v python || true)\n  if [[ -z "${PY_BIN}" ]]; then\n    echo "[validate] Manifest comparison requires python (python3 or python)." >&2\n    STATUS=1\n  else\n    REPORT_FILE="${OUT_DIR%/}/validation_report.log"\n    if ! "${PY_BIN}" "${BASE_DIR}/scripts/semantic_manifest.py" --outputs "${OUT_DIR}" --manifest "${MANIFEST}" --report "${REPORT_FILE}" --processed-count "${files_processed}"; then\n      STATUS=1\n    fi\n  fi\nfi\n\nexit ${STATUS}\n
