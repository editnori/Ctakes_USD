#!/usr/bin/env bash\nset -euo pipefail\n\nORIGINAL_ARGS=("$@")\n\nBASE_DIR="$(cd "$(dirname "$0")/.." && pwd)"\nENV_FILE="${BASE_DIR}/.ctakes_env"\nif [[ -f "${ENV_FILE}" ]]; then\n  # shellcheck disable=SC1090\n  source "${ENV_FILE}"\nfi\n\n\nRUN_PIPELINE_SCRIPT="${BASE_DIR}/scripts/run_pipeline.sh"\nRUN_PIPELINE_CMD=("${BASH:-bash}" "${RUN_PIPELINE_SCRIPT}")\n\nusage() {\n  cat <<'USAGE'\nUsage: scripts/run_async.sh -i <input_dir> -o <output_dir> [options]\nOptions:\n  --pipeline <core|sectioned|smoke|drug|core_sectioned_smoke|s_core_relations_smoke>   Pipeline key (default: sectioned)\n  --with-relations                        Enable TsRelationSubPipe (core/smoke/drug only)\n  --shards <N>                             Number of parallel runners (default: 1 or autoscale recommendation)\n  --threads <N>                            Threads per runner (passed to run_pipeline.sh)\n  --xmx <MB>                               Heap per runner in MB\n  --autoscale                              Estimate shards/threads/heap from host resources (default)\n  --no-autoscale                           Disable autoscale heuristics\n  --dict <file.xml>                        Dictionary XML to pass through\n  --umls-key <KEY>                         UMLS API key override\n  --background                             Re-run detached via nohup (logs to output dir)\n  --java-opts "..."                       Extra JVM options per runner\n  --dry-run                                Print the planned commands then exit\n  --help                                   Show this help text\n\nEach shard runs scripts/run_pipeline.sh with its own temp input folder and output folder.\nAfter all shards finish, outputs are consolidated into <output_dir>/<pipeline>/<timestamp>/...\nUSAGE\n}\n\n# Helper functions -----------------------------------------------------------\ndetect_cpus() {\n  if command -v nproc >/dev/null 2>&1; then\n    nproc\n    return\n  fi\n  case "$(uname -s 2>/dev/null)" in\n    Darwin) sysctl -n hw.ncpu ;;\n    MINGW*|MSYS*|CYGWIN*) powershell.exe -NoProfile -Command "(Get-CimInstance -ClassName Win32_ComputerSystem).NumberOfLogicalProcessors" | tr -d '\r' ;;\n    *) getconf _NPROCESSORS_ONLN 2>/dev/null || echo 1 ;;\n  esac\n}\n\ndetect_mem_mb() {\n  case "$(uname -s 2>/dev/null)" in\n    Linux) awk '/MemTotal/ { printf "%d", $2/1024 }' /proc/meminfo ;;\n    Darwin) sysctl -n hw.memsize | awk '{ printf "%d", $1/1024/1024 }' ;;\n    MINGW*|MSYS*|CYGWIN*) powershell.exe -NoProfile -Command "[math]::Round((Get-CimInstance -ClassName Win32_OperatingSystem).TotalVisibleMemorySize / 1024)" | tr -d '\r' ;;\n    *) echo 4096 ;;\n  esac\n}\n\nPIPELINE_KEY="sectioned"\nWITH_RELATIONS=0\nSHARDS=""\nSHARDS_SET=0\nBACKGROUND=0\nTHREADS=""\nTHREADS_SET=0\nXMX=""\nXMX_SET=0\nAUTOSCALE=1\nDICT_XML=""\nUMLS_OVERRIDE=""\nJAVA_OPTS_EXTRA=""\nDRY_RUN=0\nIN_DIR=""\nOUT_DIR=""\n\nwhile [[ $# -gt 0 ]]; do\n  case "$1" in\n    -i|--input) IN_DIR="$2"; shift 2;;\n    -o|--output) OUT_DIR="$2"; shift 2;;\n    --pipeline) PIPELINE_KEY="$2"; shift 2;;\n    --with-relations) WITH_RELATIONS=1; shift 1;;\n    --shards) SHARDS="$2"; SHARDS_SET=1; shift 2;;\n    --threads) THREADS="$2"; THREADS_SET=1; shift 2;;\n    --xmx) XMX="$2"; XMX_SET=1; shift 2;;\n    --autoscale) AUTOSCALE=1; shift 1;;\n    --no-autoscale) AUTOSCALE=0; shift 1;;\n    --dict) DICT_XML="$2"; shift 2;;\n    --umls-key) UMLS_OVERRIDE="$2"; shift 2;;\n    --java-opts) JAVA_OPTS_EXTRA="$2"; shift 2;;\n    --background) BACKGROUND=1; shift 1;;\n    --dry-run) DRY_RUN=1; shift 1;;\n    --help|-h) usage; exit 0;;\n    *) echo "Unknown option: $1" >&2; usage >&2; exit 1;;\n  esac\n\ndone\n\nif [[ -z "${IN_DIR}" || -z "${OUT_DIR}" ]]; then\n  echo "[async] --input and --output are required" >&2\n  usage >&2\n  exit 1\nfi\n\n[[ -d "${IN_DIR}" ]] || { echo "[async] Input directory not found: ${IN_DIR}" >&2; exit 1; }\nif [[ ${BACKGROUND} -eq 1 && -z "${CTAKES_ASYNC_REEXEC:-}" ]]; then\n  if [[ ${DRY_RUN} -eq 1 ]]; then\n    echo "[async] --background cannot be combined with --dry-run" >&2\n    exit 1\n  fi\n  if ! command -v nohup >/dev/null 2>&1; then\n    echo "[async] --background requires nohup" >&2\n    exit 1\n  fi\n  LOG_DIR="${OUT_DIR%/}"\n  mkdir -p "${LOG_DIR}"\n  LOG_FILE="${LOG_DIR}/run_async.log"\n  REPLAY_ARGS=()\n  for arg in "${ORIGINAL_ARGS[@]}"; do\n    [[ "$arg" == "--background" ]] && continue\n    REPLAY_ARGS+=("$arg")\n  done\n  export CTAKES_ASYNC_REEXEC=1\n  nohup "${BASH:-bash}" "$0" "${REPLAY_ARGS[@]}" >>"${LOG_FILE}" 2>&1 &\n  child_pid=$!\n  echo "[async] background mode enabled; output -> ${LOG_FILE} (pid ${child_pid})"\n  exit 0\nfi\n\n\nif [[ ! -f "${RUN_PIPELINE_SCRIPT}" ]]; then\n  echo "[async] Missing run_pipeline.sh helper" >&2\n  exit 1\nfi\n\nmapfile -t FILES < <(find "$IN_DIR" -type f -name '*.txt' -print | sort)\nif [[ ${#FILES[@]} -eq 0 ]]; then\n  echo "[async] No .txt files found under ${IN_DIR}" >&2\n  exit 1\nfi\nTOTAL_DOCS=${#FILES[@]}\n\nif [[ ${AUTOSCALE} -eq 1 ]]; then\n  cpus=$(detect_cpus); [[ -z "$cpus" || "$cpus" -lt 1 ]] && cpus=1\n  mem=$(detect_mem_mb); [[ -z "$mem" || "$mem" -lt 1024 ]] && mem=4096\n  max_workers=$(( cpus > 1 ? cpus - 1 : 1 ))\n  if [[ ${SHARDS_SET} -eq 0 ]]; then\n    if (( cpus >= 16 )); then\n      SHARDS=4\n    elif (( cpus >= 8 )); then\n      SHARDS=3\n    elif (( cpus >= 4 )); then\n      SHARDS=2\n    else\n      SHARDS=1\n    fi\n  fi\n  (( SHARDS < 1 )) && SHARDS=1\n  if (( SHARDS > TOTAL_DOCS )); then SHARDS=$TOTAL_DOCS; fi\n  if [[ ${THREADS_SET} -eq 0 ]]; then\n    threads_rec=$(( max_workers / SHARDS ))\n    (( threads_rec < 1 )) && threads_rec=1\n    if (( cpus >= 4 && threads_rec < 2 )); then threads_rec=2; fi\n    (( threads_rec > 12 )) && threads_rec=12\n    THREADS=$threads_rec\n  fi\n  if [[ ${XMX_SET} -eq 0 ]]; then\n    divisor=$SHARDS\n    (( divisor < 1 )) && divisor=1\n    per_runner=$(( (mem * 70 / 100) / divisor ))\n    (( per_runner < 4096 )) && per_runner=4096\n    (( per_runner > 32768 )) && per_runner=32768\n    XMX=$per_runner\n  fi\n  echo "[async] autoscale -> shards=${SHARDS}, threads=${THREADS:-"-"}, Xmx=${XMX:-"-"}MB" >&2\nfi\n\nif [[ -z "${SHARDS}" ]]; then SHARDS=1; fi\nif (( SHARDS < 1 )); then SHARDS=1; fi\nif (( SHARDS > TOTAL_DOCS )); then SHARDS=$TOTAL_DOCS; fi\nif [[ -z "${THREADS}" ]]; then THREADS=2; fi\n(( THREADS < 1 )) && THREADS=1\nif [[ -z "${XMX}" ]]; then XMX=4096; fi\n\nTIMESTAMP=$(date +%Y%m%d-%H%M%S)\nBASE_OUT="${OUT_DIR%/}/${PIPELINE_KEY}/${TIMESTAMP}"\nSHARDS_DIR="${BASE_OUT}/shards"\nmkdir -p "$SHARDS_DIR"\ndeclare -A PID_TO_INDEX=()\ndeclare -a SHARD_DOCS=()\nSTART_TS=$(date +%s)\n\ndeclare -a SHARD_COUNTS\n\necho "[async] ===== Starting async run for pipeline '${PIPELINE_KEY}' ====="\nprintf '[async] total docs=%d | shards=%d | threads=%s | Xmx=%sMB\n' "$TOTAL_DOCS" "$SHARDS" "${THREADS:-"-"}" "${XMX:-"-"}"\nprintf '[async] input=%s -> output=%s\n' "$IN_DIR" "$OUT_DIR"\n\nfor ((i=0;i<SHARDS;i++)); do\n  shard_dir=$(printf "%s/shard-%03d/input" "$SHARDS_DIR" "$i")\n  mkdir -p "$shard_dir"\n  SHARD_COUNTS[$i]=0\ndone\n\nfor ((idx=0; idx<TOTAL_DOCS; idx++)); do\n  shard=$(( idx % SHARDS ))\n  dest=$(printf "%s/shard-%03d/input" "$SHARDS_DIR" "$shard")\n  src="${FILES[$idx]}"\n  SHARD_COUNTS[$shard]=$(( ${SHARD_COUNTS[$shard]:-0} + 1 ))\n  ln "$src" "$dest/" 2>/dev/null || cp -f "$src" "$dest/"\ndone\n\nCOMMON_ARGS=(--pipeline "$PIPELINE_KEY")\nif [[ $WITH_RELATIONS -eq 1 ]]; then\n  COMMON_ARGS+=(--with-relations)\nfi\n[[ -n $DICT_XML ]] && COMMON_ARGS+=(--dict "$DICT_XML")\n[[ -n $UMLS_OVERRIDE ]] && COMMON_ARGS+=(--umls-key "$UMLS_OVERRIDE")\n[[ -n $JAVA_OPTS_EXTRA ]] && COMMON_ARGS+=(--java-opts "$JAVA_OPTS_EXTRA")\n[[ -n $THREADS ]] && COMMON_ARGS+=(--threads "$THREADS")\n[[ -n $XMX ]] && COMMON_ARGS+=(--xmx "$XMX")\n\nif [[ $DRY_RUN -eq 1 ]]; then\n  for ((i=0;i<SHARDS;i++)); do\n    in_dir=$(printf "%s/shard-%03d/input" "$SHARDS_DIR" "$i")\n    out_dir=$(printf "%s/shard-%03d/output" "$SHARDS_DIR" "$i")\n    printf 'RUNNER_INDEX=%s RUNNER_COUNT=%s ' "$((i+1))" "$SHARDS"\n    printf '%q ' "${RUN_PIPELINE_CMD[@]}" --input "$in_dir" --output "$out_dir"\n    printf '%q ' "${COMMON_ARGS[@]}"\n    printf '\n'\n  done\n  exit 0\nfi\n\nPIDS=()\nSTATUS=0\ntrap 'for pid in "${PIDS[@]}"; do kill "$pid" 2>/dev/null || true; done' INT TERM\n\nfor ((i=0;i<SHARDS;i++)); do\n  in_dir=$(printf "%s/shard-%03d/input" "$SHARDS_DIR" "$i")\n  out_dir=$(printf "%s/shard-%03d/output" "$SHARDS_DIR" "$i")\n  mkdir -p "$out_dir"\n  docs=${SHARD_COUNTS[$i]:-0}\n  log_file=$(printf "%s/shard-%03d/output/run.log" "$SHARDS_DIR" "$i")\n  printf '[async] shard-%03d | docs=%d | threads=%s | Xmx=%sMB -> %s\n' "$i" "$docs" "${THREADS:-"-"}" "${XMX:-"-"}" "$out_dir"\n  (\n    printf '[async] shard-%03d started at %s\n' "$i" "$(date '+%Y-%m-%d %H:%M:%S')"\n    runner_idx=$((i+1))\n    RUNNER_INDEX=$runner_idx RUNNER_COUNT=$SHARDS "${RUN_PIPELINE_CMD[@]}" --input "$in_dir" --output "$out_dir" "${COMMON_ARGS[@]}"\n    status=$?\n    printf '[async] shard-%03d finished at %s (exit=%d)\n' "$i" "$(date '+%Y-%m-%d %H:%M:%S')" "$status"\n    exit $status\n  ) >"$log_file" 2>&1 &\n  pid=$!\n  PIDS+=($pid)\n  PID_TO_INDEX[$pid]=$i\n  SHARD_DOCS[$i]=$docs\ndone\ncompleted=0\nfailed=0\ndocs_done=0\nfor pid in "${PIDS[@]}"; do\n  if wait "$pid"; then\n    exit_code=0\n  else\n    exit_code=$?\n  fi\n  shard_index=${PID_TO_INDEX[$pid]:-0}\n  shard_label=$(printf "shard-%03d" "$shard_index")\n  shard_docs=${SHARD_DOCS[$shard_index]:-0}\n  docs_done=$((docs_done + shard_docs))\n  completed=$((completed + 1))\n  percent=$((completed * 100 / SHARDS))\n  elapsed=$(( $(date +%s) - START_TS ))\n  if (( exit_code == 0 )); then\n    echo "[async] progress ${completed}/${SHARDS} (${percent}%) | docs ${docs_done}/${TOTAL_DOCS} | elapsed ${elapsed}s | ${shard_label} ok"\n  else\n    failed=$((failed + 1))\n    STATUS=1\n    echo "[async] progress ${completed}/${SHARDS} (${percent}%) | docs ${docs_done}/${TOTAL_DOCS} | elapsed ${elapsed}s | ${shard_label} exit=${exit_code}" >&2\n  fi\ndone\n\nTOTAL_ELAPSED=$(( $(date +%s) - START_TS ))\nif (( STATUS == 0 )); then\n  echo "[async] all shards completed in ${TOTAL_ELAPSED}s"\nelse\n  echo "[async] completed with ${failed} failure(s) in ${TOTAL_ELAPSED}s" >&2\nfi\n\nmkdir -p "$BASE_OUT/xmi" "$BASE_OUT/concepts" "$BASE_OUT/cui_counts"\nif [[ $PIPELINE_KEY == "drug" ]]; then\n  mkdir -p "$BASE_OUT/rxnorm"\nfi\n\nfor shard_out in "$SHARDS_DIR"/shard-*/output; do\n  [[ -d "$shard_out" ]] || continue\n  if [[ -d "$shard_out/xmi" ]]; then\n    cp -f "$shard_out"/xmi/* "$BASE_OUT/xmi/" 2>/dev/null || true\n  fi\n  if [[ -d "$shard_out/concepts" ]]; then\n    cp -f "$shard_out"/concepts/* "$BASE_OUT/concepts/" 2>/dev/null || true\n  fi\n  if [[ -d "$shard_out/cui_counts" ]]; then\n    cp -f "$shard_out"/cui_counts/* "$BASE_OUT/cui_counts/" 2>/dev/null || true\n  fi\n  if [[ -d "$shard_out/rxnorm" ]]; then\n    mkdir -p "$BASE_OUT/rxnorm"\n    cp -f "$shard_out"/rxnorm/* "$BASE_OUT/rxnorm/" 2>/dev/null || true\n  fi\n  if [[ -f "$shard_out/run.log" ]]; then\n    mkdir -p "$BASE_OUT/logs"\n    cp -f "$shard_out/run.log" "$BASE_OUT/logs/$(basename "$(dirname "$shard_out")").log" || true\n  fi\ndone\n\ncombine_delimited_dir() {\n  local src_dir="$1"; local dest_file="$2"; local extension="$3"\n  local first_written=0\n  >"$dest_file"\n  shopt -s nullglob\n  for file in "$src_dir"/*."${extension}" "$src_dir"/*."${extension^^}"; do\n    [[ -f "$file" ]] || continue\n    if [[ $first_written -eq 0 ]]; then\n      cat "$file" >> "$dest_file"\n      first_written=1\n    else\n      tail -n +2 "$file" >> "$dest_file"\n    fi\n  done\n  shopt -u nullglob\n  if [[ $first_written -eq 0 ]]; then rm -f "$dest_file"; fi\n}\nif compgen -G "$BASE_OUT/concepts/*.csv" >/dev/null 2>&1; then\n  combine_delimited_dir "$BASE_OUT/concepts" "$BASE_OUT/concepts_summary.csv" csv\nfi\nif [[ -d "$BASE_OUT/rxnorm" ]] && compgen -G "$BASE_OUT/rxnorm/*.csv" >/dev/null 2>&1; then\n  combine_delimited_dir "$BASE_OUT/rxnorm" "$BASE_OUT/rxnorm_summary.csv" csv\nfi\n\nif compgen -G "$BASE_OUT/cui_counts/*.bsv" >/dev/null 2>&1; then\n  combine_delimited_dir "$BASE_OUT/cui_counts" "$BASE_OUT/cui_counts_summary.bsv" bsv\nfi\n\nprintf '[async] Outputs ready at %s\n' "$BASE_OUT"\nexit $STATUS\n\n\n
